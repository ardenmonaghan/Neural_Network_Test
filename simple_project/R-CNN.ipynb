{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with R-CNNs Understanding the architecture and how it works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Important Terms:\n",
    "\n",
    "- Region Proposal: A region proposal is a rectangular area on an image that contains an object.\n",
    "- Bounding Box: A bounding box is a rectangle that surrounds an object in an image.\n",
    "- Region Proposal Network (RPN): A region proposal network is a neural network that generates region proposals.\n",
    "- Region of Interest (ROI): A region of interest is a rectangular area on an image that contains an object.\n",
    "- Convolutions are a type of neural network layer that perform feature extraction on an image.\n",
    "- Pooling is a type of neural network layer that reduces the size of an image.\n",
    "- Feature map: A feature map is a 2D grid of values that represent the output of a convolutional layer.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-CNNs\n",
    "\n",
    "- Main Idea: We use an external algorithm to generate a set of possible bounding boxes that we can classify. RPN + CNN.\n",
    "\n",
    "1. Region Proposal (RPN): Use an external algorithm like (Selective Search) to generate a set of possible bounding boxes that we can classify.\n",
    "2. Extract Region Proposals and then make them square (fixed size)\n",
    "3. Run them through a CNN to describe the region proposals.\n",
    "4. Use the outputted class describing each region. We use Bounding Boxes to refine the region. \n",
    "(The CNN step returns The class label, and the bounding box offsets that we need to apply to the region to get the final bounding box.)\n",
    "\n",
    "(px, py, w, h) are the coordinates of the bounding box. \n",
    "(tx, ty, tw, th) are the transformed coordinates of the bounding box. \n",
    "(bx, by, bh, bw) are the new coordiantes of the region after applying the transformation. \n",
    "\n",
    "Where the transformation is: \n",
    "\n",
    "\n",
    "(px, py) are the coordinates of the top left corner of the bounding box. \n",
    "(w, h) are the width and height of the bounding box. \n",
    "\n",
    "If you see (10, 20, 50 ,60) this mean the top left corner of the bounding box is at (10, 20) and the width and height are 50 and 60 respectively. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: WE will use a pre defined model which has a CNN backbone included. Modern R-CNNS do not use SVM.\n",
    "A RPN is a region proposal network (something like Selective Search that helps us find possible bounds.)\n",
    "\n",
    "Note: R-CNNs, for each bounding box "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clarification: \n",
    "1. A CNN has Convolution and pooling layers\n",
    "2. Fully connected layers\n",
    "3. Output layer with probabilities for each class\n",
    "4. Argmax choosing the highest probability class\n",
    "\n",
    "## SVMs \n",
    "- trying to find a hyperplane that best seperates the data between classes. \n",
    "\"Where can i put a boundary so that we can try and obtain all different classes end up on different sides\"\n",
    "\n",
    "## R-CNNS\n",
    "\n",
    "In the original R-CNNs We\n",
    "1. Propose Regions\n",
    "2. Extract Features with CNN 4096-d vector is the final output of the CNN. Numerical feature representation of the patch. We run CNN for each bounding box.\n",
    "3. Now classifiy with a SVM. 4096-d vector for each region proposal R-CNN trains a seperate SVM classifier for each class. As we update the weights we get closer \n",
    "to the best hyperplane. SVM in an n-dimensional feature space is 1 seperation hyperplane for a binary classification. \n",
    "- In original R-CNN, the CNN’s final fully-connected layer (often a 4096-dimensional vector) is treated purely as a feature extractor. This 4096-D feature vector is then passed to a set of SVMs—one SVM per class—each of which learns a hyperplane (in that 4096-D space) to separate “this class” from “not this class.”\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Faster R-CNNs\n",
    "uses CNN directly to produce a probability distribution for each region.\n",
    "\n",
    "- So like lets say theres a person and a helmet, fast R-cnn will identify the helmet using CNN with probabilities as the final layer and maximum will correspond to the class right?\n",
    "- That’s correct. In Fast R-CNN, once a region proposal is generated (say, “this patch might contain an object”), the network’s final classification head outputs a probability distribution over all possible classes. No separate SVM step is needed; it’s all done by the CNN’s final “fully-connected + softmax” layer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNNs\n",
    "\n",
    "- Faster R-CNNs use a Regional Proposal Network (RPN) to generate region proposals instead of Selective Search.\n",
    "- Has ROI pooling layer "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
